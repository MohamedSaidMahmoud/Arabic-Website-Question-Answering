{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#web scraping"
      ],
      "metadata": {
        "id": "Zs71EhcAJlCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Install required packages"
      ],
      "metadata": {
        "id": "qLFCeUpKJu9X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ib0U4AwIiQo",
        "outputId": "3220f6d2-3aed-4f53-c137-fe25fcb297ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting firecrawl\n",
            "  Downloading firecrawl-2.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from firecrawl) (2.32.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from firecrawl) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from firecrawl) (1.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from firecrawl) (2.11.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from firecrawl) (3.11.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl) (2.3.0)\n",
            "Downloading firecrawl-2.1.1-py3-none-any.whl (36 kB)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, firecrawl, anthropic\n",
            "Successfully installed anthropic-0.49.0 firecrawl-2.1.1 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install firecrawl anthropic beautifulsoup4 python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import required libraries"
      ],
      "metadata": {
        "id": "Y97tQqefKB3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "from firecrawl import FirecrawlApp\n",
        "import anthropic\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "qoMx9aHRJ-_p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###API keys\n",
        "#####- [Anthropic API](https://www.anthropic.com) (API key required)\n",
        "#####- [Firecrawl API](https://www.firecrawl.com) (API key required)"
      ],
      "metadata": {
        "id": "xCkQsvw1KwnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"FIRECRAWL_API_KEY\"] = getpass(\"Enter your FIRECRAWL API key: \")\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter your ANTHROPIC API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H25PUN_qKEo7",
        "outputId": "ec630c08-cfed-448c-80ce-3424d9d59b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your FIRECRAWL API key: ··········\n",
            "Enter your ANTHROPIC API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define the article URL to scrape"
      ],
      "metadata": {
        "id": "K5zGgrs5Lki-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.aljazeera.net/sport/2025/4/18/barca-arsenal\""
      ],
      "metadata": {
        "id": "k0MHm1KLLkGW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize Firecrawl and Anthropic clients using API keys"
      ],
      "metadata": {
        "id": "wVHM7BeLLx5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firecrawl_key = os.environ[\"FIRECRAWL_API_KEY\"]\n",
        "anthropic_key = os.environ[\"ANTHROPIC_API_KEY\"]\n",
        "\n",
        "client = anthropic.Client(api_key=anthropic_key)\n",
        "app = FirecrawlApp(api_key=firecrawl_key)"
      ],
      "metadata": {
        "id": "KWBJgLPVLw43"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Scrape the URL content using Firecrawl"
      ],
      "metadata": {
        "id": "Gw6OB8GdL-hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_result = app.scrape_url(url, formats=['html'])\n",
        "\n",
        "# Check if scraping succeeded\n",
        "if not scrape_result:\n",
        "    print(\"Failed to fetch data from the URL.\")\n",
        "else:\n",
        "    print(\"Page content fetched successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMezeOniL6Wn",
        "outputId": "d2d3bf06-6723-4bbf-ae89-f9ecd3ab295f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page content fetched successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Functions to extract title and main content from HTML"
      ],
      "metadata": {
        "id": "5GPYSBQwMKdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_title_from_html(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    title_tag = soup.find('title')\n",
        "    if title_tag:\n",
        "        return title_tag.get_text(strip=True)\n",
        "    return \"No Title Found\"\n",
        "\n",
        "def extract_main_content_from_html(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Remove script and style elements\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.decompose()\n",
        "\n",
        "    # Try to locate the main content\n",
        "    main_content = soup.select_one('main#main-content-area')\n",
        "\n",
        "    if main_content:\n",
        "        # Clean known unwanted blocks\n",
        "        for unwanted in main_content.select('.article-info-block, .disclaimer-text, .article-author, .article-dates'):\n",
        "            unwanted.decompose()\n",
        "\n",
        "        # Extract paragraphs\n",
        "        content = [p.get_text(strip=True) for p in main_content.find_all('p')]\n",
        "        return '\\n'.join(content)\n",
        "\n",
        "    return \"No Main Content Found\""
      ],
      "metadata": {
        "id": "j_1x0R3EMA8u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extract title & content, display them, and save to a .txt file"
      ],
      "metadata": {
        "id": "3fGyccSKMV_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if scrape_result:\n",
        "    html = scrape_result.html\n",
        "\n",
        "    title = extract_title_from_html(html)\n",
        "    main_content = extract_main_content_from_html(html)\n",
        "\n",
        "    # Show title and main content before saving\n",
        "    print(f\"Title:\\n{title}\\n\")\n",
        "    print(f\"Main Content:\\n{main_content}\\n\")\n",
        "\n",
        "    # Save to a .txt file\n",
        "    output_path = 'output.txt'\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"Title:\\n{title}\\n\\n\")\n",
        "        f.write(f\"Main Content:\\n{main_content}\\n\")\n",
        "\n",
        "    print(f\"Title and main content saved to {output_path}\")\n",
        "else:\n",
        "    print(\"No scrape result to process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWiXYhRSMTGO",
        "outputId": "de91a13f-ef6e-40a2-8be9-e9684ac5eb5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:\n",
            "إغلاق تلميح الأدوات\n",
            "\n",
            "Main Content:\n",
            "مع اكتمال عقد الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم، كشف حاسوب عملاق عن توقعاته لحظوظ الفرق الأربعة في التتويج باللقب.\n",
            "وبلغت أندية كل من برشلونة وإنتر ميلان وأرسنال وباريس سان جيرمان الدور نصف النهائي من المسابقة الأوروبية العريقة بعد تجاوزها عقبة كل من بوروسيا دورتموند وبايرن ميونخ وريال مدريد وأستون فيلا على الترتيب.\n",
            "\n",
            "وبحسب صحيفة \"سبورت\" الإسبانية فإن النسب المئوية التي حددها حاسوب \"أوبتا\" العملاق قد أثارت جدلا واسعا على مواقع التواصل الاجتماعي خاصة بعد أن وضع برشلونة في ذيل قائمة الفرق المرشحة للتتويج باللقب.\n",
            "ويُعتبر أرسنال المرشح الأبرز لتحقيق اللقب بعد أن أقصى ريال مدريد حامل اللقب بنتيجة 5-1 في مجموع مباراتي الذهاب والإياب، بنسبة 28.7%.\n",
            "اللافت أن هذه المرة الأولى التي يتصدر فيها أرسنال توقعات الذكاء الاصطناعي للفوز بالكأس \"ذات الأذنين\" هذا الموسم.\n",
            "\n",
            "وحل إنتر ميلان ثانيا بعد بلوغه المربع الذهبي على حساب بايرن ميونخ بعد مباراتين قويتين مثيرتين، حيث بلغت نسبة تتويجه بدوري الأبطال وفق حاسوب \"أوبتا\" 25.5%.\n",
            "ومنح الحاسوب العملاق نسبة 24% لسان جيرمان الذي تجاوز بصعوبة بالغة عقبة أستون فيلا بعد معاناة كبيرة في الإياب.\n",
            "أما المفاجأة الكبرى من وجهة نظر \"سبورت\" فتتمثل في وجود برشلونة بالمركز الأخير من حيث الترشيح للتتويج باللقب حيث بلغت نسبة حدوث ذلك 21.8% فقط.\n",
            "ومن المرجّح أن يكون سبب ذلك أن برشلونة الفريق -الذي تلقى الهزيمة الأكبر في مرحلة الإياب- بين الرباعي المذكور (1-3) رغم أنه فاز ذهابا على بوروسيا دورتموند بنتيجة عريضة استقرت عند 4-0.\n",
            "\n",
            "أرسنال X سان جيرمان على ملعب الإمارات (الذهاب)\n",
            "برشلونة X إنتر ميلان على ملعب مونتجويك (الذهاب)\n",
            "إنتر ميلان X برشلونة على ملعب سان سيرو (الإياب)\n",
            "باريس سان جيرمان X أرسنال على ملعب حديقة الأمراء (الإياب)\n",
            "\n",
            "Title and main content saved to output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JgDorwDbMsx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}