{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Question Answering System"
      ],
      "metadata": {
        "id": "ESsUEuKMzpE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Web Scraping"
      ],
      "metadata": {
        "id": "Sc38QNgizwGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install required packages"
      ],
      "metadata": {
        "id": "mbbrF03Kz0OQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMiONybtzkj3",
        "outputId": "93be3914-d61a-48fc-9065-4c5cdeeb078d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from firecrawl) (2.32.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from firecrawl) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from firecrawl) (1.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from firecrawl) (2.11.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from firecrawl) (3.11.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->firecrawl) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->firecrawl) (1.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->firecrawl) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install firecrawl anthropic beautifulsoup4 python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import required libraries"
      ],
      "metadata": {
        "id": "3Tyn9tluz8vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "from firecrawl import FirecrawlApp\n",
        "import anthropic\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "cHBvKJd8z_Z0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###API keys\n",
        "#####- [Anthropic API](https://www.anthropic.com) (API key required)\n",
        "#####- [Firecrawl API](https://www.firecrawl.com) (API key required)"
      ],
      "metadata": {
        "id": "nt34P2V_0Acb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"FIRECRAWL_API_KEY\"] = getpass(\"Enter your FIRECRAWL API key: \")\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter your ANTHROPIC API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTP00tRs0Dt_",
        "outputId": "b8fa16f0-5cde-4e8c-eef1-1e9f765da272"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your FIRECRAWL API key: ··········\n",
            "Enter your ANTHROPIC API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define the article URL to scrape"
      ],
      "metadata": {
        "id": "qpMy4ZDo0H9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.aljazeera.net/sport/2025/4/18/barca-arsenal\""
      ],
      "metadata": {
        "id": "8xeBv-lz0JzT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize Firecrawl and Anthropic clients using API keys"
      ],
      "metadata": {
        "id": "h5fGnCxC0L8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firecrawl_key = os.environ[\"FIRECRAWL_API_KEY\"]\n",
        "anthropic_key = os.environ[\"ANTHROPIC_API_KEY\"]\n",
        "\n",
        "client = anthropic.Client(api_key=anthropic_key)\n",
        "app = FirecrawlApp(api_key=firecrawl_key)"
      ],
      "metadata": {
        "id": "I9OnHlrV0NeC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Scrape the URL content using Firecrawl"
      ],
      "metadata": {
        "id": "5Aq8L1DF0N_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_result = app.scrape_url(url, formats=['html'])\n",
        "\n",
        "# Check if scraping succeeded\n",
        "if not scrape_result:\n",
        "    print(\"Failed to fetch data from the URL.\")\n",
        "else:\n",
        "    print(\"Page content fetched successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGlcTCky0P-C",
        "outputId": "5e0fee5a-c4b8-4181-e00e-a6db94ce3f01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page content fetched successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Functions to extract title and main content from HTML"
      ],
      "metadata": {
        "id": "iXAKzIH_0SgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_title_from_html(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    title_tag = soup.find('title')\n",
        "    if title_tag:\n",
        "        return title_tag.get_text(strip=True)\n",
        "    return \"No Title Found\"\n",
        "\n",
        "def extract_main_content_from_html(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Remove script and style elements\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.decompose()\n",
        "\n",
        "    # Try to locate the main content\n",
        "    main_content = soup.select_one('main#main-content-area')\n",
        "\n",
        "    if main_content:\n",
        "        # Clean known unwanted blocks\n",
        "        for unwanted in main_content.select('.article-info-block, .disclaimer-text, .article-author, .article-dates'):\n",
        "            unwanted.decompose()\n",
        "\n",
        "        # Extract paragraphs\n",
        "        content = [p.get_text(strip=True) for p in main_content.find_all('p')]\n",
        "        return '\\n'.join(content)\n",
        "\n",
        "    return \"No Main Content Found\""
      ],
      "metadata": {
        "id": "_ZZ8U55n0WO6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extract title & content, display them, and save to a .txt file"
      ],
      "metadata": {
        "id": "zy6wD1qM0YOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if scrape_result:\n",
        "    html = scrape_result.html\n",
        "\n",
        "    title = extract_title_from_html(html)\n",
        "    main_content = extract_main_content_from_html(html)\n",
        "\n",
        "    # Show title and main content before saving\n",
        "    print(f\"Title:\\n{title}\\n\")\n",
        "    print(f\"Main Content:\\n{main_content}\\n\")\n",
        "\n",
        "    # Save to a .txt file\n",
        "    output_path = 'output.txt'\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"Title:\\n{title}\\n\\n\")\n",
        "        f.write(f\"Main Content:\\n{main_content}\\n\")\n",
        "\n",
        "    print(f\"Title and main content saved to {output_path}\")\n",
        "else:\n",
        "    print(\"No scrape result to process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fPMg6KC0aCa",
        "outputId": "32c89b9b-a949-4ff7-83e7-d91c84187f48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:\n",
            "إغلاق تلميح الأدوات\n",
            "\n",
            "Main Content:\n",
            "مع اكتمال عقد الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم، كشف حاسوب عملاق عن توقعاته لحظوظ الفرق الأربعة في التتويج باللقب.\n",
            "وبلغت أندية كل من برشلونة وإنتر ميلان وأرسنال وباريس سان جيرمان الدور نصف النهائي من المسابقة الأوروبية العريقة بعد تجاوزها عقبة كل من بوروسيا دورتموند وبايرن ميونخ وريال مدريد وأستون فيلا على الترتيب.\n",
            "\n",
            "وبحسب صحيفة \"سبورت\" الإسبانية فإن النسب المئوية التي حددها حاسوب \"أوبتا\" العملاق قد أثارت جدلا واسعا على مواقع التواصل الاجتماعي خاصة بعد أن وضع برشلونة في ذيل قائمة الفرق المرشحة للتتويج باللقب.\n",
            "ويُعتبر أرسنال المرشح الأبرز لتحقيق اللقب بعد أن أقصى ريال مدريد حامل اللقب بنتيجة 5-1 في مجموع مباراتي الذهاب والإياب، بنسبة 28.7%.\n",
            "اللافت أن هذه المرة الأولى التي يتصدر فيها أرسنال توقعات الذكاء الاصطناعي للفوز بالكأس \"ذات الأذنين\" هذا الموسم.\n",
            "\n",
            "وحل إنتر ميلان ثانيا بعد بلوغه المربع الذهبي على حساب بايرن ميونخ بعد مباراتين قويتين مثيرتين، حيث بلغت نسبة تتويجه بدوري الأبطال وفق حاسوب \"أوبتا\" 25.5%.\n",
            "ومنح الحاسوب العملاق نسبة 24% لسان جيرمان الذي تجاوز بصعوبة بالغة عقبة أستون فيلا بعد معاناة كبيرة في الإياب.\n",
            "أما المفاجأة الكبرى من وجهة نظر \"سبورت\" فتتمثل في وجود برشلونة بالمركز الأخير من حيث الترشيح للتتويج باللقب حيث بلغت نسبة حدوث ذلك 21.8% فقط.\n",
            "ومن المرجّح أن يكون سبب ذلك أن برشلونة الفريق -الذي تلقى الهزيمة الأكبر في مرحلة الإياب- بين الرباعي المذكور (1-3) رغم أنه فاز ذهابا على بوروسيا دورتموند بنتيجة عريضة استقرت عند 4-0.\n",
            "\n",
            "أرسنال X سان جيرمان على ملعب الإمارات (الذهاب)\n",
            "برشلونة X إنتر ميلان على ملعب مونتجويك (الذهاب)\n",
            "إنتر ميلان X برشلونة على ملعب سان سيرو (الإياب)\n",
            "باريس سان جيرمان X أرسنال على ملعب حديقة الأمراء (الإياب)\n",
            "\n",
            "Title and main content saved to output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAG (Retrieval-Augmented Generation)"
      ],
      "metadata": {
        "id": "xSMalNFr0kGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Text Files"
      ],
      "metadata": {
        "id": "jVB7DHE41IJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List to hold all documents (in this case, one long document)\n",
        "texts = []\n",
        "\n",
        "# Read the file and store it as a single document\n",
        "with open(\"/content/output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "    texts.append(content)\n",
        "\n",
        "print(f\"Loaded {len(texts)} document(s). Sample:\\n\\n{texts[0][:1000]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vXvFqcf1Eft",
        "outputId": "bcb81e7c-4b7a-436d-bbc1-d1673f8ff3b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 document(s). Sample:\n",
            "\n",
            "Title:\n",
            "إغلاق تلميح الأدوات\n",
            "\n",
            "Main Content:\n",
            "مع اكتمال عقد الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم، كشف حاسوب عملاق عن توقعاته لحظوظ الفرق الأربعة في التتويج باللقب.\n",
            "وبلغت أندية كل من برشلونة وإنتر ميلان وأرسنال وباريس سان جيرمان الدور نصف النهائي من المسابقة الأوروبية العريقة بعد تجاوزها عقبة كل من بوروسيا دورتموند وبايرن ميونخ وريال مدريد وأستون فيلا على الترتيب.\n",
            "\n",
            "وبحسب صحيفة \"سبورت\" الإسبانية فإن النسب المئوية التي حددها حاسوب \"أوبتا\" العملاق قد أثارت جدلا واسعا على مواقع التواصل الاجتماعي خاصة بعد أن وضع برشلونة في ذيل قائمة الفرق المرشحة للتتويج باللقب.\n",
            "ويُعتبر أرسنال المرشح الأبرز لتحقيق اللقب بعد أن أقصى ريال مدريد حامل اللقب بنتيجة 5-1 في مجموع مباراتي الذهاب والإياب، بنسبة 28.7%.\n",
            "اللافت أن هذه المرة الأولى التي يتصدر فيها أرسنال توقعات الذكاء الاصطناعي للفوز بالكأس \"ذات الأذنين\" هذا الموسم.\n",
            "\n",
            "وحل إنتر ميلان ثانيا بعد بلوغه المربع الذهبي على حساب بايرن ميونخ بعد مباراتين قويتين مثيرتين، حيث بلغت نسبة تتويجه بدوري الأبطال وفق حاسوب \"أوبتا\" 25.5%.\n",
            "ومنح الحاسوب العمل\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare the Embedding Model"
      ],
      "metadata": {
        "id": "YG6DgiM11LVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence_transformers"
      ],
      "metadata": {
        "id": "d9x4iU4H30NX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Embedding class to handle document and query embeddings\n",
        "class EmbeddingModel:\n",
        "    def __init__(self):\n",
        "        # Load multilingual transformer model\n",
        "        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2').to(device)\n",
        "\n",
        "    def embed_documents(self, docs):\n",
        "        # Convert documents into embeddings\n",
        "        embeddings = self.model.encode(docs, convert_to_tensor=True, device=device)\n",
        "        return embeddings.cpu().numpy().tolist()\n",
        "\n",
        "    def embed_query(self, query):\n",
        "        # Convert single query into embedding\n",
        "        embeddings = self.model.encode(query, convert_to_tensor=True, device=device)\n",
        "        return embeddings.cpu().numpy().tolist()\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = EmbeddingModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfzQH7NM1QQa",
        "outputId": "c63b134c-e030-4f9f-f8d9-4994e01b2dc3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Chroma Vector Database"
      ],
      "metadata": {
        "id": "kx2l9u6m1SbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_chroma"
      ],
      "metadata": {
        "id": "g99YnjNA1V3p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Function to embed documents in batches and store in Chroma vector DB\n",
        "def batch_upsert(texts, batch_size, embed_model):\n",
        "    vector_database = None\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        embeddings = embed_model.embed_documents(batch_texts)\n",
        "\n",
        "        if vector_database is None:\n",
        "            vector_database = Chroma.from_texts(\n",
        "                texts=batch_texts,\n",
        "                embedding=embed_model,\n",
        "                metadatas=None,\n",
        "                ids=None,\n",
        "            )\n",
        "        else:\n",
        "            vector_database.add_texts(\n",
        "                texts=batch_texts,\n",
        "                embeddings=embeddings\n",
        "            )\n",
        "    return vector_database\n",
        "\n",
        "# Set batch size and run upsert\n",
        "batch_size = 20000\n",
        "vector_database = batch_upsert(texts, batch_size, embed_model)\n",
        "\n",
        "# Convert vector database to retriever\n",
        "retriever = vector_database.as_retriever(search_type='similarity', search_kwargs={'k': 3})"
      ],
      "metadata": {
        "id": "jyrC_K6a1WZJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try retrieving similar articles using a sample question\n",
        "sample_question = \"ما هي الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم؟\"\n",
        "similar_docs = retriever.invoke(sample_question)\n",
        "\n",
        "# Print the top 3 similar documents\n",
        "for i, doc in enumerate(similar_docs):\n",
        "    print(f\"\\nArticle {i+1}:\\n{doc.page_content[:500]}...\")  # Print first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXCDm4RQ8csa",
        "outputId": "f1136c0b-ca93-498a-a0a0-9c3999356801"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Article 1:\n",
            "Title:\n",
            "إغلاق تلميح الأدوات\n",
            "\n",
            "Main Content:\n",
            "مع اكتمال عقد الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم، كشف حاسوب عملاق عن توقعاته لحظوظ الفرق الأربعة في التتويج باللقب.\n",
            "وبلغت أندية كل من برشلونة وإنتر ميلان وأرسنال وباريس سان جيرمان الدور نصف النهائي من المسابقة الأوروبية العريقة بعد تجاوزها عقبة كل من بوروسيا دورتموند وبايرن ميونخ وريال مدريد وأستون فيلا على الترتيب.\n",
            "\n",
            "وبحسب صحيفة \"سبورت\" الإسبانية فإن النسب المئوية التي حددها حاسوب \"أوبتا\" العملاق قد أثارت جدلا واسعا على مواقع التوا...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build the Prompt Template and RAG Chain"
      ],
      "metadata": {
        "id": "Ml2evgYH1Zp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJDY1eJc4vdW",
        "outputId": "c5a27fa0-0618-44a9-9a3b-f65cb5e92940"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.6.17)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.52)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    google_api_key=\"AIzaSyBMrcWQfNlHxyQNzhj0cOWyebJkSBHhS-g\"\n",
        ")\n",
        "\n",
        "# Create a prompt template for the question answering\n",
        "template = \"\"\"\n",
        "You are an intelligent and contextually aware Arabic AI assistant designed to provide precise and detailed responses to customer questions. Your task is to use the information retrieved from the knowledge base to generate a comprehensive and accurate answer.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Contextual Information:\n",
        "{context}\n",
        "\n",
        "Provide a clear and concise Arabic answer based on the context provided.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Format the context from documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Build the final RAG chain\n",
        "context_chain = retriever | format_docs\n",
        "rag_chain = (\n",
        "    {\"context\": context_chain, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "EV9S5S1E2DhY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Try the Full RAG Chain on a Sample Question"
      ],
      "metadata": {
        "id": "nc7Xv0JJ2EQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question\n",
        "question = \"ما هي الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم؟\"\n",
        "\n",
        "# Use the RAG chain to get an answer\n",
        "answer = rag_chain.invoke(question)\n",
        "\n",
        "# Print the answer\n",
        "print(\"Answer to the Question:\\n\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NE4d0qs2HeZ",
        "outputId": "a295d2ce-cf22-4e1b-82f4-8f54a2b1e94e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer to the Question:\n",
            "\n",
            "الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم هي: برشلونة، وإنتر ميلان، وأرسنال، وباريس سان جيرمان.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save the Answer to a Text File"
      ],
      "metadata": {
        "id": "E-LT6KD52VCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(question):\n",
        "    \"\"\"Processes the question and returns relevant articles and the final answer.\"\"\"\n",
        "\n",
        "    # 1. Retrieve similar articles\n",
        "    similar_docs = retriever.invoke(question)\n",
        "    articles = [doc.page_content for doc in similar_docs]  # Assuming you want content only\n",
        "\n",
        "    # 2. Generate the answer using the RAG chain\n",
        "    answer = rag_chain.invoke(question)\n",
        "\n",
        "    return articles, answer\n",
        "\n",
        "\n",
        "# Save the answer to a text file\n",
        "ans = process_question(\"ما هي الفرق المتأهلة إلى نصف نهائي دوري أبطال أوروبا لكرة القدم؟\")\n",
        "\n",
        "with open(\"/content/answer.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(ans[1])  # تأكد من أن ans[1] هي الإجابة النهائية\n",
        "\n",
        "print(\"Answer has been saved to /content/answer.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMYdWwyj2YpR",
        "outputId": "66c20d5d-2c57-4128-d5e4-af6e35afe3e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer has been saved to /content/answer.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradio UI"
      ],
      "metadata": {
        "id": "_Uo4XZqz2Lph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVYlD8Nn2Jux",
        "outputId": "7e603277-efea-459f-b1b2-83ac957871c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def rag_interface(question):\n",
        "    _, answer = process_question(question)\n",
        "    return answer\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=rag_interface,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Answer to the Question\")\n",
        "    ],\n",
        "    title=\"Arabic Question Answering System\",\n",
        "    description=\"Enter a question to receive an answer.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "nnIi-7Kt2URg",
        "outputId": "67e10694-eba1-4f39-ba48-3739199db17e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://adbe5a6c7820cb97f4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://adbe5a6c7820cb97f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}